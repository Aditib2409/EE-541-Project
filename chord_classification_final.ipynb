{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kaw6dWE7xi-H"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch \n",
    "import torchaudio\n",
    "import IPython\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.io import wavfile\n",
    "from scipy.fft import fft, fftfreq\n",
    "from scipy.signal import spectrogram, find_peaks\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QNBo_ufhxtaH",
    "outputId": "37e64de1-ee54-470e-be54-4c65a1bef8a4"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jmue1eNLDZTB"
   },
   "source": [
    "### Unzipping datasets and merging them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5SF5E1YZzTnX",
    "outputId": "fd842d43-be36-4412-8053-9b90e818c42f"
   },
   "outputs": [],
   "source": [
    "!unzip \"/content/drive/Shareddrives/EE541Project/archive.zip\"   # 859 datapoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AACUnyw-13HZ"
   },
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RgG8lhpI39Uy"
   },
   "outputs": [],
   "source": [
    "class loading_dataset:\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "\n",
    "    def harmonics(self, file_path, print=False):\n",
    "        freq, X = wavfile.read(file_path)\n",
    "        n = len(X)   \n",
    "        X_fourier = fft(X)\n",
    "        X_fourier_onesided = 2.0/n * np.abs(X_fourier[0:n // 2])\n",
    "        frequencies = fftfreq(n, 1/freq)[:n//2]\n",
    "        freqs_50_index = np.argmin(np.abs(frequencies - 50))\n",
    "        \n",
    "        ht = np.max(X_fourier_onesided)*5/100\n",
    "        peaks_found, _ = find_peaks(X_fourier_onesided, distance=10, height=ht)\n",
    "        peaks_found = peaks_found[peaks_found>freqs_50_index]\n",
    "        harmonics_found = np.round(frequencies[peaks_found],2)\n",
    "\n",
    "        if print:\n",
    "            p = np.max(peaks_found) + 100\n",
    "            plt.plot(frequencies[:p], X_fourier_onesided[:p])\n",
    "            plt.plot(frequencies[peaks_found], X_fourier_onesided[peaks_found], 'o')\n",
    "            plt.xlabel(f'Frequency in Hz')\n",
    "            plt.ylabel(f'Harmonics')\n",
    "            plt.show()\n",
    "        \n",
    "        return harmonics_found\n",
    "\n",
    "    \n",
    "    def create_dataframe(self):\n",
    "        # to track the length of a harmonic\n",
    "        length_harmonic = 0\n",
    "        dataset = []\n",
    "\n",
    "        for dir_name, _, file_name in os.walk(self.path):\n",
    "            for filename in file_name:\n",
    "                folder_name = os.path.basename(dir_name)\n",
    "                full_filepath = os.path.join(dir_name, filename)\n",
    "                harmonic_peaks = self.harmonics(full_filepath)\n",
    "                min_harmonics = harmonic_peaks.min()\n",
    "                max_harmonics = harmonic_peaks.max()\n",
    "                num_peaks = len(harmonic_peaks)\n",
    "                length_harmonic = max(num_peaks, length_harmonic)\n",
    "                current_data = [folder_name, filename, min_harmonics, max_harmonics, num_peaks] \n",
    "                current_data.extend(harmonic_peaks)\n",
    "\n",
    "                dataset.append(current_data)\n",
    "\n",
    "        feature_cols = [\"Chord_type\", \"File_name\", \"Minimum_harmonic\", \"Maximum_harmonic\", \"Num_harmonics\"]\n",
    "        for i in range(length_harmonic):\n",
    "            feature_cols.append(f'Harmonic {i+1}')\n",
    "\n",
    "        data_df = pd.DataFrame(dataset, columns=feature_cols)\n",
    "\n",
    "        return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FZrYBXbfAD2q"
   },
   "outputs": [],
   "source": [
    "path = \"/content/Audio_Files\"\n",
    "dataloader = loading_dataset(path)\n",
    "data = dataloader.create_dataframe()\n",
    "data_og = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vvrOAKkqJmo4"
   },
   "outputs": [],
   "source": [
    "def plot_kde(I, df):\n",
    "    rows = len(I)\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=rows, figsize=(25, 3), sharex=True, sharey=True)\n",
    "    axes = axes.ravel()\n",
    "    for i in range(rows):\n",
    "        if i <= len(I)-1:\n",
    "            sns.kdeplot(ax=axes[i], data=df, x=I[i], hue=\"Chord_type\", shade=True, palette=\"Set2\")\n",
    "    fig.suptitle(f'KDE plots of Selected Features')\n",
    "    plt.savefig(f'/content/drive/Shareddrives/EE541Project/Figures/Data Preprocessing/kde_intervals.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ShkziaknsMw"
   },
   "outputs": [],
   "source": [
    "def plot_kde_features(I, df):\n",
    "    fig, axes = plt.subplots(nrows=9, ncols=3, figsize=(15, 35))\n",
    "    axs = axes.ravel()\n",
    "    for i in range(len(I)):\n",
    "        if i <= len(I)-1:\n",
    "            sns.kdeplot(ax=axs[i], data=df, x=I[i], hue=\"Chord_type\", shade=True)\n",
    "    plt.savefig(f'/content/drive/Shareddrives/EE541Project/Figures/Data Preprocessing/kde_features.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bb820Aw0_LVK"
   },
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LDp_QQZZ_OAw"
   },
   "outputs": [],
   "source": [
    "major_path = \"/content/Audio_Files/Major/Major_1.wav\"\n",
    "minor_path = \"/content/Audio_Files/Minor/Minor_1.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 61
    },
    "id": "1oR9lXFo_QnG",
    "outputId": "14889abf-6029-4ae9-fc5f-233a96d102b3"
   },
   "outputs": [],
   "source": [
    "IPython.display.Audio(major_path, rate = 44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 61
    },
    "id": "bAd-nKqO_STT",
    "outputId": "0107c4ed-eed6-48d9-bf39-5e4e43ad61bb"
   },
   "outputs": [],
   "source": [
    "IPython.display.Audio(minor_path, rate = 44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iCD0vMr2_XkP"
   },
   "outputs": [],
   "source": [
    "def plot_chord_signals(path, cclass, c):\n",
    "    sample_freq, audio_signal = wavfile.read(path)\n",
    "    time = np.linspace(0, len(audio_signal)/sample_freq, len(audio_signal))\n",
    "\n",
    "    # Fourier Transform\n",
    "    y_freq = fftfreq(len(audio_signal), 1/sample_freq)[:len(audio_signal)//2]  # array for frequency stamps\n",
    "    signal_freq = fft(audio_signal) # Signal in frequency domain\n",
    "    signal_freq_onesided = 2.0/len(audio_signal) * np.abs(signal_freq[0:len(audio_signal)//2]) # taking positive terms\n",
    "\n",
    "    # Plotting signal in time and frequency domains\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    axes[0].plot(time, audio_signal, color=c)\n",
    "    axes[0].set_title(f\"{cclass} Chord Wave in Time Domain\")\n",
    "    axes[0].set(xlabel='Time (s)')\n",
    "    axes[1].plot(y_freq[:1500], signal_freq_onesided[:1500], color=c)\n",
    "    axes[1].set_title(f\"{cclass} Chord Wave in Frequency Domain\")\n",
    "    axes[1].set(xlabel='Frequency (Hz)')\n",
    "    plt.savefig(f'/content/drive/Shareddrives/EE541Project/Figures/Data Preprocessing/{cclass}_signal.png')\n",
    "    plt.show()\n",
    "\n",
    "    freq, time, Sxx = spectrogram(audio_signal, sample_freq, nperseg=10000, nfft = 50000)\n",
    "    plt.figure()\n",
    "    plt.pcolormesh(time, freq, np.log(Sxx), cmap=\"CMRmap\")\n",
    "    plt.title(f\"Spectogram of {cclass} Chord\")\n",
    "    plt.xlabel('Time(s)')\n",
    "    plt.ylabel('Frequency(Hz)')\n",
    "    plt.savefig(f'/content/drive/Shareddrives/EE541Project/Figures/Data Preprocessing/{cclass}_spectrogram.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 590
    },
    "id": "H_TUYjI3_ZyH",
    "outputId": "a5ea131e-5dfa-4aaa-d25f-e3fb07a96585"
   },
   "outputs": [],
   "source": [
    "plot_chord_signals(major_path, \"Major\", \"orange\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "8f-f-xvA_mSK",
    "outputId": "11ab007c-31a7-4441-9f30-c983d21c788e"
   },
   "outputs": [],
   "source": [
    "plot_chord_signals(minor_path, \"Minor\", \"c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BqlzlQLkIvl2"
   },
   "source": [
    "### Creating intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "49Gj0VmJAYkA",
    "outputId": "1cfd168f-a105-475f-ef6c-5c923df32bd4"
   },
   "outputs": [],
   "source": [
    "intervals = [\"octave\", \"quinta\", \"quarta\", \"major inertia\", \"minor inertia\"]\n",
    "for i in range(len(intervals)):\n",
    "    data[intervals[i]] = np.divide(data[f'Harmonic {i+2}'], data[f'Harmonic {i+1}'])\n",
    "\n",
    "# adding more intervals\n",
    "for i in range(len(intervals)):\n",
    "    for j in range(i+1, len(intervals)):\n",
    "        data[f'interval_{i+1}_{j+1}'] = np.divide(data[intervals[j]], data[intervals[i]])\n",
    "\n",
    "## gives list of all harmonics that have NANs. we drop those harmonics\n",
    "data.isnull().sum(axis = 0)\n",
    "\n",
    "drop_harmonics = data.columns[13:43] ## NAN values\n",
    "data = data.drop(drop_harmonics, axis=1)\n",
    "data = data.drop(\"File_name\", axis=1)\n",
    "new_list = list(data.columns)\n",
    "plot_kde_features(new_list[1:], data)\n",
    "data[\"Chord_type\"] = data[\"Chord_type\"].replace(\"Major\", 0)\n",
    "data[\"Chord_type\"] = data[\"Chord_type\"].replace(\"Minor\", 1)\n",
    "data_y = data[\"Chord_type\"]\n",
    "new_data = data.drop(\"Chord_type\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J9-DQ8fFb7jg"
   },
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oE9Qp3Fp_18c"
   },
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(new_data, data_y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2WDvzXhW_3d4"
   },
   "outputs": [],
   "source": [
    "test_csv = pd.concat([test_x, test_y], axis=1)\n",
    "test_csv.to_csv(\"/content/drive/Shareddrives/EE541Project/Data/Test\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sH77UrZrwoWt"
   },
   "outputs": [],
   "source": [
    "def get_selected_features(df, y, df_test):\n",
    "    data_x = df\n",
    "    normalizer = StandardScaler()\n",
    "    data_norm = normalizer.fit_transform(data_x)\n",
    "    \n",
    "\n",
    "    pca = PCA()\n",
    "    data_pca = pca.fit_transform(data_norm)\n",
    "\n",
    "    explained_variance = pca.explained_variance_ratio_\n",
    "    plt.plot(explained_variance, marker='o', color='black')\n",
    "    plt.title('Variances in each component')\n",
    "    plt.xlabel('num of features')\n",
    "    plt.ylabel('variances')\n",
    "\n",
    "    for i in range(len(explained_variance)):\n",
    "        sum_variances = explained_variance[0:i].sum()\n",
    "        if sum_variances > 0.99:\n",
    "            num_components = i\n",
    "            break\n",
    "    \n",
    "    y0 = explained_variance[num_components]\n",
    "    plt.plot(num_components, y0, marker='s', color='red', label=f\"num_components={num_components}\")\n",
    "    plt.legend()\n",
    "    plt.savefig(f'/content/drive/Shareddrives/EE541Project/Figures/Data Preprocessing/pca_variances.png')\n",
    "\n",
    "\n",
    "    ## Recursive feature analysis\n",
    "    model_tree = RandomForestClassifier(random_state=100, n_estimators=50)\n",
    "    sel_rfe_tree = RFE(estimator=model_tree, n_features_to_select=num_components, step=1)\n",
    "    X_train_rfe_tree = sel_rfe_tree.fit_transform(data_norm, y)\n",
    "    sel_feature_indices = sel_rfe_tree.ranking_\n",
    "    # print(sel_feature_indices)\n",
    "\n",
    "    sel_columns = data_x.columns[np.where(sel_feature_indices == 1)]\n",
    "\n",
    "    plot_kde(sel_columns, data)\n",
    "\n",
    "    data_transformed_train = data_x[sel_columns]\n",
    "    data_transformed_test = df_test[sel_columns]\n",
    "\n",
    "    return data_transformed_train, data_transformed_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "t9G114LYxKVy",
    "outputId": "02730d0c-3499-4e6a-fefa-8186b1899dda"
   },
   "outputs": [],
   "source": [
    "train_x, test_x  = get_selected_features(train_x, train_y, test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vGQiUVMdADGq"
   },
   "outputs": [],
   "source": [
    "df = train_x\n",
    "df[\"Chord_type\"] = train_y\n",
    "sns.pairplot(df, hue=\"Chord_type\", diag_kind=\"hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fmk0z-NwPSjV"
   },
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(data_x, pd.Series(data_y, name=\"chord_type\"), test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dLWHaJABhfN4"
   },
   "outputs": [],
   "source": [
    "train_csv = pd.concat([train_x, train_y], axis=1)\n",
    "test_csv = pd.concat([test_x, test_y], axis=1)\n",
    "train_csv.to_csv(\"/content/drive/Shareddrives/EE541Project/Data/Train\", encoding='utf-8', index=False)\n",
    "test_csv.to_csv(\"/content/drive/Shareddrives/EE541Project/Data/Test\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5TTtto8HzsuX"
   },
   "source": [
    "# Model Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IM9u_La6bB2y"
   },
   "outputs": [],
   "source": [
    "# Loading train and test data (both features and labels)\n",
    "traindata = pd.read_table(\"/content/drive/Shareddrives/EE541Project/Data/Train\",\n",
    "                          sep=',')\n",
    "testdata = pd.read_table(\"/content/drive/Shareddrives/EE541Project/Data/Test\",\n",
    "                          sep=',')\n",
    "X_train = traindata.iloc[:, :-1]\n",
    "Y_train = traindata.iloc[:, -1]\n",
    "X_test = testdata.iloc[:, :-1]\n",
    "Y_test = testdata.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KIt-ksJwZ3SA"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "\n",
    "# Functions\n",
    "def calcAccuracy(labels, preds):\n",
    "    return np.mean(labels == preds)\n",
    "\n",
    "def plotConfMat(labels, preds, filename=None):\n",
    "    confmat = confusion_matrix(labels, preds)\n",
    "    sns.set(rc={\"figure.figsize\":(8, 6)})\n",
    "    p = sns.heatmap(confmat, annot=True, fmt='g')\n",
    "    p.set_xlabel(\"Prediction\", fontsize = 20)\n",
    "    p.set_ylabel(\"Reference\", fontsize = 20)\n",
    "    \n",
    "    if filename is not None:\n",
    "        fig = p.get_figure()\n",
    "        fig.savefig(filename)\n",
    "        fig.clf()\n",
    "\n",
    "accuracy = {}\n",
    "f1_score = {}\n",
    "precision = {}\n",
    "recall = {}\n",
    "roc_auc = {}\n",
    "test_accuracy = {}\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators = 1000, random_state = 42)\n",
    "# Naive Bayes\n",
    "nb = GaussianNB()\n",
    "# SVM:\n",
    "svc_l = SVC(kernel='linear')     # Linear kernel\n",
    "svc_p = SVC(kernel='poly')   # polynomial kernel\n",
    "svc_r = SVC(kernel='rbf')        # radial kernel\n",
    "\n",
    "models = {'RandomForest':rf, 'NaiveBayes':nb, 'SVM linear':svc_l,\n",
    "          'SVM polynomial':svc_p, 'SVM radial':svc_r}\n",
    "\n",
    "# Calculate the metrics for all ML models\n",
    "# Plot confusion matrices on test data\n",
    "for name, model in models.items():\n",
    "    accuracy[name] = cross_val_score(model, X_train, Y_train, cv=10,\n",
    "                                     scoring='accuracy')\n",
    "    f1_score[name] = cross_val_score(model, X_train, Y_train, cv=10,\n",
    "                                     scoring='f1')\n",
    "    precision[name] = cross_val_score(model, X_train, Y_train, cv=10,\n",
    "                                      scoring='precision')\n",
    "    recall[name] = cross_val_score(model, X_train, Y_train, cv=10,\n",
    "                                   scoring='recall')\n",
    "    roc_auc[name] = cross_val_score(model, X_train, Y_train, cv=10,\n",
    "                                    scoring='roc_auc')\n",
    "    \n",
    "    model.fit(X_train, Y_train)\n",
    "    Y_hat = model.predict(X_test)\n",
    "    test_accuracy[name] = calcAccuracy(Y_test, Y_hat)\n",
    "    plotConfMat(Y_test, Y_hat, filename=f\"/content/drive/Shareddrives/EE541Project/Figures/models/confmat_{name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NGxpM4TSrRLV"
   },
   "outputs": [],
   "source": [
    "# Plotting evaluation metric of each model\n",
    "measure = 'roc_auc'\n",
    "temp_df = pd.DataFrame(roc_auc)\n",
    "temp_df = pd.melt(temp_df, var_name='model', value_name=measure)\n",
    "sns.set(rc={\"figure.figsize\":(8, 6)})\n",
    "ax = sns.boxplot(x='model', y=measure, data=temp_df)\n",
    "fig = ax.get_figure()\n",
    "fig.savefig(f\"/content/drive/Shareddrives/EE541Project/Figures/models/ML_crossval_{measure}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "id": "9ilGrdbeDRYr",
    "outputId": "ddd4481f-60f5-466b-f18f-41670a7ff8d9"
   },
   "outputs": [],
   "source": [
    "# Plotting the test accuracy of all models.\n",
    "sns.set(rc={\"figure.figsize\":(8, 6)})\n",
    "p = sns.barplot(x=list(test_accuracy.keys()), y=list(test_accuracy.values()))\n",
    "p.set_xlabel(\"Prediction\", fontsize = 20)\n",
    "p.set_ylabel(\"Reference\", fontsize = 20)\n",
    "fig = p.get_figure()\n",
    "fig.savefig(\"/content/drive/Shareddrives/EE541Project/Figures/models/test_accuracy.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jTCVNh9QM6lk"
   },
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lBjEsNoX92Gr"
   },
   "outputs": [],
   "source": [
    "# Defining neural network\n",
    "class ChordClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, dropout_rate, dims, activation_func='relu'):\n",
    "        super(ChordClassifier, self).__init__()\n",
    "\n",
    "        # use nn.Sequential module to wrap up all the layers\n",
    "        if activation_func == 'relu':\n",
    "            self.net = nn.Sequential(\n",
    "                nn.Linear(dims['input'], dims['hidden_1']),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(dims['hidden_1'], dims['hidden_2']),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(dims['hidden_2'], dims['output']),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "        elif activation_func == 'tanh':\n",
    "            self.net = nn.Sequential(\n",
    "                nn.Linear(dims['input'], dims['hidden_1']),\n",
    "                nn.Tanh(),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(dims['hidden_1'], dims['hidden_2']),\n",
    "                nn.Tanh(),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(dims['hidden_2'], dims['output']),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.net(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EFHaYLqHOdDa"
   },
   "outputs": [],
   "source": [
    "# train-validation-test split\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(X_train, Y_train,\n",
    "                                                      test_size=0.15)\n",
    "x_train = x_train.to_numpy()\n",
    "y_train = y_train.to_numpy()[..., np.newaxis]\n",
    "x_valid = x_valid.to_numpy()\n",
    "y_valid = y_valid.to_numpy()[..., np.newaxis]\n",
    "X_test = X_test.to_numpy()\n",
    "Y_test = Y_test.to_numpy()[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-0_bs3qPOeMO"
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "dropout_rate = 0\n",
    "activation_func = 'relu'\n",
    "learning_rate = 0.01 # low learning rate\n",
    "lmb = 0.001 # L2-regularization\n",
    "epochs = 3000\n",
    "dims = {\n",
    "    'input': 7,\n",
    "    'hidden_1': 5,\n",
    "    'hidden_2': 3,\n",
    "    'output': 1\n",
    "       }\n",
    "\n",
    "# build a binary classification model\n",
    "model = ChordClassifier(dropout_rate=dropout_rate, dims=dims,\n",
    "                        activation_func=activation_func)\n",
    "\n",
    "# create optimizer and loss instances\n",
    "opt = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=lmb)\n",
    "loss_func = nn.BCELoss()\n",
    "\n",
    "# start training\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "train_accs = []\n",
    "valid_accs = []\n",
    "dummy_accs = []\n",
    "\n",
    "x_train = torch.Tensor(x_train)\n",
    "y_train = torch.Tensor(y_train)\n",
    "x_valid = torch.Tensor(x_valid)\n",
    "y_valid = torch.Tensor(y_valid)\n",
    "\n",
    "for ep in range(epochs):\n",
    "    model.train()\n",
    "    \n",
    "    \n",
    "    y_hat = model(x_train)\n",
    "    loss = loss_func(y_hat, y_train)\n",
    "    y_hat_valid = model(x_valid)\n",
    "    loss_valid = loss_func(y_hat_valid, y_valid)\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    train_losses.append(loss.data.numpy())\n",
    "    valid_losses.append(loss_valid.data.numpy())\n",
    "    \n",
    "    y_hat = torch.Tensor.round(y_hat)\n",
    "    y_hat_valid = torch.Tensor.round(y_hat_valid)\n",
    "    train_acc = (y_hat == y_train).float()    \n",
    "    train_acc = torch.Tensor.mean(train_acc)\n",
    "    valid_acc = torch.Tensor.mean((y_hat_valid == y_valid).float())\n",
    "    train_accs.append(train_acc.item())\n",
    "    valid_accs.append(valid_acc.item())\n",
    "\n",
    "    opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wcxI7nWZYkWr",
    "outputId": "c31f210e-a300-4292-c318-77573084f7d4"
   },
   "outputs": [],
   "source": [
    "# Model architecture\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zZsyj_HFYXEE"
   },
   "source": [
    "### Neural Network model accuracy on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k47ENJV8YP6M",
    "outputId": "b189132e-85b8-4106-990a-ebd01186b7e4"
   },
   "outputs": [],
   "source": [
    "X_test = torch.Tensor(X_test)\n",
    "Y_test = torch.Tensor(Y_test)\n",
    "y_hat_test = model(X_test)\n",
    "\n",
    "y_hat_test = torch.Tensor.round(y_hat_test)\n",
    "test_acc = torch.Tensor.mean((y_hat_test == Y_test).float()).item()\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "g-D31rNVWHzw",
    "outputId": "9d5ac119-f5fc-45f6-da80-29ff03d2e27f"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 5))\n",
    "plt.plot(train_accs)\n",
    "plt.plot(valid_accs)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.title(f\"epochs:{epochs}, activation:{activation_func}, learning_rate:{learning_rate}, lambda:{lmb}, dropout rate:{dropout_rate}\")\n",
    "plt.savefig(f'/content/drive/Shareddrives/EE541Project/Figures/models/nn_accuracy_{test_acc}.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "DcwshvqhX3lG",
    "outputId": "fbfb260f-f647-48db-c884-984ba3b6887e"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 5))\n",
    "plt.plot(train_losses)\n",
    "plt.plot(valid_losses)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Losses')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.title(f\"epochs:{epochs}, activation:{activation_func}, learning rate:{learning_rate}, lambda:{lmb}, dropout rate:{dropout_rate}\")\n",
    "plt.savefig(f'/content/drive/Shareddrives/EE541Project/Figures/models/nn_losses_{test_acc}.png', dpi=150)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chord_classification_final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
